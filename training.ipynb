{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3133,"status":"ok","timestamp":1690312214034,"user":{"displayName":"Jake Moore","userId":"04266473620751372556"},"user_tz":0},"id":"VbXJEai6lfvd"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-29 16:25:00.769084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-29 16:25:14.091748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Using TensorFlow backend\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import keras_cv\n","from keras import layers\n","from keras.models import Sequential\n","from keras.optimizers import Adam"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1690312216734,"user":{"displayName":"Jake Moore","userId":"04266473620751372556"},"user_tz":0},"id":"2mSfDIvjrtTM","outputId":"dea43fce-f117-4221-cbbd-e2a83706b319"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-29 16:25:24.938591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-29 16:25:27.149981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-29 16:25:27.150248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"]}],"source":["physical_devices = tf.config.list_physical_devices('GPU')\n","tf.config.experimental.set_memory_growth(physical_devices[0], True)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":66852,"status":"error","timestamp":1690312398905,"user":{"displayName":"Jake Moore","userId":"04266473620751372556"},"user_tz":0},"id":"YhLRS_rnlvA0","outputId":"3fecd907-ddef-407d-b809-5cd3c2950ce0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 24051 files belonging to 2 classes.\n","Using 20444 files for training.\n","Found 24051 files belonging to 2 classes.\n","Using 3607 files for validation.\n"]}],"source":["train_data = tf.keras.utils.image_dataset_from_directory(\n","    '../earthshots-data/model-datasets/train', # update this\n","    validation_split = .15,\n","    subset='training',\n","    seed=0,\n","    image_size = (224, 224),\n","    batch_size=32,\n",")\n","\n","val_data = tf.keras.utils.image_dataset_from_directory(\n","    '../earthshots-data/model-datasets/train',\n","    validation_split=.15,\n","    subset='validation',\n","    seed=0,\n","    image_size=(224,224),\n","    batch_size=32,\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1233,"status":"ok","timestamp":1690299838820,"user":{"displayName":"Jake Moore","userId":"04266473620751372556"},"user_tz":0},"id":"ueuEdbI3pSM9"},"outputs":[],"source":["model = tf.keras.applications.ResNet101V2(\n","    weights=None,\n","    input_shape=(224,224,3),\n","    classes=1,\n","    classifier_activation=\"sigmoid\",\n",")\n","\n","# model = tf.keras.models.load_model('models/airfields-effnetV2S-2.keras')\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["lr = .001\n","\n","batch_increase = 1\n","\n","k = batch_increase ** .5\n","\n","lr = lr * k\n","\n","optimizer = tf.keras.optimizers.RMSprop(\n","    learning_rate=lr,\n",")\n","\n","acc_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n","prec_callback = tf.keras.callbacks.EarlyStopping(monitor='val_precision', patience=5, restore_best_weights=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1690299840087,"user":{"displayName":"Jake Moore","userId":"04266473620751372556"},"user_tz":0},"id":"tEcVW0N0sDC4"},"outputs":[],"source":["model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision()])"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nO6YYZo9pqQ1","outputId":"67ae120a-3570-4433-8e3b-e4ad49484852"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stdout","output_type":"stream","text":["639/639 [==============================] - 165s 186ms/step - loss: 0.2589 - accuracy: 0.9031 - precision_2: 0.7721 - val_loss: 0.6217 - val_accuracy: 0.8303 - val_precision_2: 1.0000\n","Epoch 2/100\n","639/639 [==============================] - 114s 178ms/step - loss: 0.1744 - accuracy: 0.9340 - precision_2: 0.8455 - val_loss: 0.7067 - val_accuracy: 0.8356 - val_precision_2: 1.0000\n","Epoch 3/100\n","639/639 [==============================] - 113s 177ms/step - loss: 0.1497 - accuracy: 0.9439 - precision_2: 0.8715 - val_loss: 0.7309 - val_accuracy: 0.8298 - val_precision_2: 0.8000\n","Epoch 4/100\n","639/639 [==============================] - 113s 177ms/step - loss: 0.1312 - accuracy: 0.9510 - precision_2: 0.8803 - val_loss: 0.2255 - val_accuracy: 0.9263 - val_precision_2: 0.9403\n","Epoch 5/100\n","639/639 [==============================] - 114s 177ms/step - loss: 0.1159 - accuracy: 0.9568 - precision_2: 0.8952 - val_loss: 0.3265 - val_accuracy: 0.9149 - val_precision_2: 0.9700\n","Epoch 6/100\n","639/639 [==============================] - 113s 177ms/step - loss: 0.1065 - accuracy: 0.9612 - precision_2: 0.9091 - val_loss: 0.2883 - val_accuracy: 0.9141 - val_precision_2: 0.9697\n","Epoch 7/100\n","639/639 [==============================] - 115s 180ms/step - loss: 0.0917 - accuracy: 0.9666 - precision_2: 0.9207 - val_loss: 0.2366 - val_accuracy: 0.9293 - val_precision_2: 0.9716\n","Epoch 8/100\n","639/639 [==============================] - 115s 179ms/step - loss: 0.0872 - accuracy: 0.9681 - precision_2: 0.9245 - val_loss: 0.3381 - val_accuracy: 0.9196 - val_precision_2: 0.9459\n","Epoch 9/100\n","639/639 [==============================] - 114s 177ms/step - loss: 0.0800 - accuracy: 0.9713 - precision_2: 0.9281 - val_loss: 0.7856 - val_accuracy: 0.8680 - val_precision_2: 0.9235\n","Epoch 10/100\n","639/639 [==============================] - 114s 178ms/step - loss: 0.0756 - accuracy: 0.9726 - precision_2: 0.9317 - val_loss: 0.1851 - val_accuracy: 0.9426 - val_precision_2: 0.9422\n","Epoch 11/100\n","639/639 [==============================] - 113s 176ms/step - loss: 0.0714 - accuracy: 0.9735 - precision_2: 0.9331 - val_loss: 0.1460 - val_accuracy: 0.9559 - val_precision_2: 0.9183\n","Epoch 12/100\n","639/639 [==============================] - 113s 176ms/step - loss: 0.0637 - accuracy: 0.9762 - precision_2: 0.9375 - val_loss: 0.3363 - val_accuracy: 0.9354 - val_precision_2: 0.9448\n","Epoch 13/100\n","639/639 [==============================] - 113s 176ms/step - loss: 0.0583 - accuracy: 0.9780 - precision_2: 0.9455 - val_loss: 0.1162 - val_accuracy: 0.9620 - val_precision_2: 0.9671\n","Epoch 14/100\n","639/639 [==============================] - 113s 177ms/step - loss: 0.0550 - accuracy: 0.9802 - precision_2: 0.9478 - val_loss: 0.1379 - val_accuracy: 0.9629 - val_precision_2: 0.9534\n","Epoch 15/100\n","639/639 [==============================] - 112s 176ms/step - loss: 0.0485 - accuracy: 0.9825 - precision_2: 0.9522 - val_loss: 0.2142 - val_accuracy: 0.9504 - val_precision_2: 0.9419\n","Epoch 16/100\n","639/639 [==============================] - 108s 169ms/step - loss: 0.0487 - accuracy: 0.9830 - precision_2: 0.9545 - val_loss: 0.5009 - val_accuracy: 0.9157 - val_precision_2: 0.9759\n","Epoch 17/100\n","639/639 [==============================] - 105s 164ms/step - loss: 0.0429 - accuracy: 0.9836 - precision_2: 0.9546 - val_loss: 0.1563 - val_accuracy: 0.9648 - val_precision_2: 0.9034\n","Epoch 18/100\n","639/639 [==============================] - 108s 168ms/step - loss: 0.0401 - accuracy: 0.9856 - precision_2: 0.9619 - val_loss: 0.3469 - val_accuracy: 0.9254 - val_precision_2: 0.9655\n","Epoch 19/100\n","639/639 [==============================] - 113s 177ms/step - loss: 0.0393 - accuracy: 0.9850 - precision_2: 0.9598 - val_loss: 0.4214 - val_accuracy: 0.9107 - val_precision_2: 0.9838\n","Epoch 20/100\n","639/639 [==============================] - 112s 175ms/step - loss: 0.0347 - accuracy: 0.9875 - precision_2: 0.9680 - val_loss: 0.1947 - val_accuracy: 0.9520 - val_precision_2: 0.9497\n","Epoch 21/100\n","639/639 [==============================] - 113s 177ms/step - loss: 0.0330 - accuracy: 0.9872 - precision_2: 0.9668 - val_loss: 0.1443 - val_accuracy: 0.9565 - val_precision_2: 0.9513\n","Epoch 22/100\n","639/639 [==============================] - 113s 177ms/step - loss: 0.0305 - accuracy: 0.9901 - precision_2: 0.9740 - val_loss: 0.2867 - val_accuracy: 0.9479 - val_precision_2: 0.9219\n"]}],"source":["history = model.fit(\n","    x=train_data,\n","    validation_data = val_data,\n","    epochs = 100,\n","    callbacks=[acc_callback]\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 24051 files belonging to 2 classes.\n","Using 20444 files for training.\n","Found 24051 files belonging to 2 classes.\n","Using 3607 files for validation.\n"]}],"source":["train_data = tf.keras.utils.image_dataset_from_directory(\n","    '../earthshots-data/model-datasets/train', # update this\n","    validation_split = .15,\n","    subset='training',\n","    seed=0,\n","    image_size = (224, 224),\n","    batch_size=64,\n",")\n","\n","val_data = tf.keras.utils.image_dataset_from_directory(\n","    '../earthshots-data/model-datasets/train',\n","    validation_split=.15,\n","    subset='validation',\n","    seed=0,\n","    image_size=(224,224),\n","    batch_size=64,\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["batch_increase = 2\n","\n","k = batch_increase ** .5\n","\n","lr = lr * k\n","\n","optimizer = tf.keras.optimizers.RMSprop(\n","    learning_rate=lr,\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision()])"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2023-08-29 18:03:44.342169: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 134217728 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n"," Reported by CUDA: Free memory/Total memory: 65011712/12589203456\n","2023-08-29 18:03:44.342225: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10408755200\n","InUse:                      7519483165\n","MaxInUse:                   7519483165\n","NumAllocs:                    50370032\n","MaxAllocSize:               1538326544\n","Reserved:                            0\n","PeakReserved:                        0\n","LargestFreeBlock:                    0\n","\n","2023-08-29 18:03:44.342286: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n","2023-08-29 18:03:44.342294: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 1\n","2023-08-29 18:03:44.342300: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 62\n","2023-08-29 18:03:44.342306: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 20\n","2023-08-29 18:03:44.342312: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 2\n","2023-08-29 18:03:44.342317: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 74\n","2023-08-29 18:03:44.342322: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 80\n","2023-08-29 18:03:44.342327: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 498\n","2023-08-29 18:03:44.342334: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n","2023-08-29 18:03:44.342341: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2048, 103\n","2023-08-29 18:03:44.342348: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4096, 300\n","2023-08-29 18:03:44.342354: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8192, 39\n","2023-08-29 18:03:44.342361: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16384, 3\n","2023-08-29 18:03:44.342369: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 37632, 3\n","2023-08-29 18:03:44.342379: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 18\n","2023-08-29 18:03:44.342386: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 131072, 3\n","2023-08-29 18:03:44.342392: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 9\n","2023-08-29 18:03:44.342400: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 21\n","2023-08-29 18:03:44.342408: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 524288, 6\n","2023-08-29 18:03:44.342416: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 12\n","2023-08-29 18:03:44.342422: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 136\n","2023-08-29 18:03:44.342429: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2097152, 6\n","2023-08-29 18:03:44.342436: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 69\n","2023-08-29 18:03:44.342443: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 15\n","2023-08-29 18:03:44.342449: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6422528, 2\n","2023-08-29 18:03:44.342457: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n","2023-08-29 18:03:44.342464: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9437184, 9\n","2023-08-29 18:03:44.342472: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 12845056, 92\n","2023-08-29 18:03:44.342479: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 22\n","2023-08-29 18:03:44.342486: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 25690112, 17\n","2023-08-29 18:03:44.342497: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 29491200, 4\n","2023-08-29 18:03:44.342505: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 40627200, 1\n","2023-08-29 18:03:44.342513: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 51380224, 59\n","2023-08-29 18:03:44.342521: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 55115776, 3\n","2023-08-29 18:03:44.342527: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 102760448, 6\n","2023-08-29 18:03:44.342535: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 205520896, 4\n","2023-08-29 18:03:44.342544: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 212926464, 1\n","2023-08-29 18:03:44.342554: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 8724152320\n","2023-08-29 18:03:44.342562: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 7519483165\n","2023-08-29 18:03:44.342571: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 8724152320\n","2023-08-29 18:03:44.342579: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 7519483165\n","2023-08-29 18:03:44.343820: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 134217728 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n"," Reported by CUDA: Free memory/Total memory: 65011712/12589203456\n","2023-08-29 18:03:44.343867: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10408755200\n","InUse:                      7614391581\n","MaxInUse:                   7635494189\n","NumAllocs:                    50370059\n","MaxAllocSize:               1538326544\n","Reserved:                            0\n","PeakReserved:                        0\n","LargestFreeBlock:                    0\n","\n","2023-08-29 18:03:44.343925: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n","2023-08-29 18:03:44.343938: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 1\n","2023-08-29 18:03:44.343946: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 62\n","2023-08-29 18:03:44.343953: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 20\n","2023-08-29 18:03:44.343962: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 2\n","2023-08-29 18:03:44.343969: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 74\n","2023-08-29 18:03:44.343978: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 80\n","2023-08-29 18:03:44.343988: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 502\n","2023-08-29 18:03:44.343995: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n","2023-08-29 18:03:44.344003: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2048, 103\n","2023-08-29 18:03:44.344011: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4096, 302\n","2023-08-29 18:03:44.344018: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8192, 39\n","2023-08-29 18:03:44.344025: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16384, 3\n","2023-08-29 18:03:44.344031: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 37632, 3\n","2023-08-29 18:03:44.344037: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 18\n","2023-08-29 18:03:44.344045: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 131072, 3\n","2023-08-29 18:03:44.344051: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 9\n","2023-08-29 18:03:44.344057: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 21\n","2023-08-29 18:03:44.344064: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 524288, 6\n","2023-08-29 18:03:44.344072: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 12\n","2023-08-29 18:03:44.344079: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 135\n","2023-08-29 18:03:44.344086: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2097152, 7\n","2023-08-29 18:03:44.344093: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 69\n","2023-08-29 18:03:44.344099: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 3211264, 2\n","2023-08-29 18:03:44.344106: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 15\n","2023-08-29 18:03:44.344113: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6422528, 3\n","2023-08-29 18:03:44.344120: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n","2023-08-29 18:03:44.344127: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9437184, 9\n","2023-08-29 18:03:44.344133: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 12845056, 95\n","2023-08-29 18:03:44.344139: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 23\n","2023-08-29 18:03:44.344147: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 25690112, 18\n","2023-08-29 18:03:44.344154: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 29491200, 4\n","2023-08-29 18:03:44.344161: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 40627200, 1\n","2023-08-29 18:03:44.344168: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 51380224, 59\n","2023-08-29 18:03:44.344178: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 55115776, 3\n","2023-08-29 18:03:44.344185: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 102760448, 6\n","2023-08-29 18:03:44.344195: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 205520896, 4\n","2023-08-29 18:03:44.344202: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 212926464, 1\n","2023-08-29 18:03:44.344212: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 8724152320\n","2023-08-29 18:03:44.344222: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 7614391581\n","2023-08-29 18:03:44.344235: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 8724152320\n","2023-08-29 18:03:44.344243: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 7635494189\n","2023-08-29 18:03:44.345110: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 75497472 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n"," Reported by CUDA: Free memory/Total memory: 65011712/12589203456\n","2023-08-29 18:03:44.345161: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10408755200\n","InUse:                      7645197597\n","MaxInUse:                   7645197597\n","NumAllocs:                    50370067\n","MaxAllocSize:               1538326544\n","Reserved:                            0\n","PeakReserved:                        0\n","LargestFreeBlock:                    0\n","\n","2023-08-29 18:03:44.345219: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n","2023-08-29 18:03:44.345231: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 1\n","2023-08-29 18:03:44.345239: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 62\n","2023-08-29 18:03:44.345249: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 20\n","2023-08-29 18:03:44.345256: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 2\n","2023-08-29 18:03:44.345265: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 74\n","2023-08-29 18:03:44.345272: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 80\n","2023-08-29 18:03:44.345280: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 502\n","2023-08-29 18:03:44.345288: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n","2023-08-29 18:03:44.345297: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2048, 105\n","2023-08-29 18:03:44.345303: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4096, 302\n","2023-08-29 18:03:44.345313: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8192, 39\n","2023-08-29 18:03:44.345320: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16384, 3\n","2023-08-29 18:03:44.345329: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 37632, 3\n","2023-08-29 18:03:44.345336: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 18\n","2023-08-29 18:03:44.345342: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 131072, 3\n","2023-08-29 18:03:44.345352: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 9\n","2023-08-29 18:03:44.345358: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 21\n","2023-08-29 18:03:44.345367: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 524288, 6\n","2023-08-29 18:03:44.345373: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 12\n","2023-08-29 18:03:44.345380: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 135\n","2023-08-29 18:03:44.345389: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2097152, 6\n","2023-08-29 18:03:44.345397: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 69\n","2023-08-29 18:03:44.345406: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 3211264, 2\n","2023-08-29 18:03:44.345412: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 15\n","2023-08-29 18:03:44.345422: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6422528, 5\n","2023-08-29 18:03:44.345429: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n","2023-08-29 18:03:44.345438: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9437184, 10\n","2023-08-29 18:03:44.345445: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 10616832, 1\n","2023-08-29 18:03:44.345453: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 12845056, 95\n","2023-08-29 18:03:44.345459: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 23\n","2023-08-29 18:03:44.345466: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 25690112, 18\n","2023-08-29 18:03:44.345478: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 29491200, 4\n","2023-08-29 18:03:44.345485: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 40627200, 1\n","2023-08-29 18:03:44.345493: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 51380224, 59\n","2023-08-29 18:03:44.345499: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 55115776, 3\n","2023-08-29 18:03:44.345506: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 102760448, 6\n","2023-08-29 18:03:44.345516: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 205520896, 4\n","2023-08-29 18:03:44.345522: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 212926464, 1\n","2023-08-29 18:03:44.345535: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 8724152320\n","2023-08-29 18:03:44.345545: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 7645197597\n","2023-08-29 18:03:44.345567: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 8724152320\n","2023-08-29 18:03:44.345583: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 7645197597\n"]},{"ename":"UnknownError","evalue":"Graph execution error:\n\nDetected at node 'resnet101v2/conv5_block1_2_conv/Conv2D' defined at (most recent call last):\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3312/1901449007.py\", line 1, in <module>\n      history = model.fit(\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'resnet101v2/conv5_block1_2_conv/Conv2D'\nCUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node resnet101v2/conv5_block1_2_conv/Conv2D}}]] [Op:__inference_train_function_297585]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      2\u001b[0m     x\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[1;32m      3\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_data,\n\u001b[1;32m      4\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[acc_callback]\n\u001b[1;32m      6\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'resnet101v2/conv5_block1_2_conv/Conv2D' defined at (most recent call last):\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3312/1901449007.py\", line 1, in <module>\n      history = model.fit(\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/j/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'resnet101v2/conv5_block1_2_conv/Conv2D'\nCUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node resnet101v2/conv5_block1_2_conv/Conv2D}}]] [Op:__inference_train_function_297585]"]}],"source":["history = model.fit(\n","    x=train_data,\n","    validation_data = val_data,\n","    epochs = 100,\n","    callbacks=[acc_callback]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","prec = history.history['precision']\n","val_prec = history.history['val_precision']\n","\n","epochs_range = range(len(history))\n","\n","plt.figure(figsize=(8, 8))\n","\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","plt.show()\n","\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()\n","\n","\n","plt.plot(epochs_range, prec, label='Training Precision')\n","plt.plot(epochs_range, val_prec, label='Validation Precision')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Precision')\n","plt.show()"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ji6CqjInuOMA"},"outputs":[],"source":["model.save('models/airfields-resnet101V2-0.keras')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPknuCserUq9qPj9kECqT7N","gpuType":"T4","mount_file_id":"10duNUAuNpEZ3UrT1GLIEtbjNmnJ0md_P","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}
